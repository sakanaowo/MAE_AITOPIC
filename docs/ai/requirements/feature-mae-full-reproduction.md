---
phase: requirements
title: Requirements & Problem Understanding
description: TÃ¡i táº¡o toÃ n bá»™ model variants tá»« bÃ i bÃ¡o MAE (Masked Autoencoders Are Scalable Vision Learners)
---

# Requirements & Problem Understanding

## Problem Statement

**What problem are we solving?**

- Cáº§n tÃ¡i táº¡o (reproduce) toÃ n bá»™ kiáº¿n trÃºc model tá»« bÃ i bÃ¡o **"Masked Autoencoders Are Scalable Vision Learners"** (He et al., 2021, arXiv:2111.06377) â€” bao gá»“m cáº£ 3 biáº¿n thá»ƒ: **ViT-Base**, **ViT-Large**, **ViT-Huge**.
- Hiá»‡n táº¡i code Ä‘Ã£ implement rá»i ráº¡c trong `mae/mae.py` (ViT-Base) vÃ  `mae/mae_large.py` (ViT-Large), nhÆ°ng:
  - ChÆ°a cÃ³ ViT-Huge
  - `encoder.py` vÃ  `decoder.py` cÃ²n **rá»—ng** â€” chÆ°a tÃ¡ch module encoder/decoder riÃªng biá»‡t
  - Thiáº¿u factory functions thá»‘ng nháº¥t Ä‘á»ƒ táº¡o model
  - ChÆ°a cÃ³ folder trÃ¬nh bÃ y chuyÃªn biá»‡t cho tá»«ng model variant
  - Thiáº¿u documentation rÃµ rÃ ng mapping giá»¯a paper â†’ code
- Äá»‘i tÆ°á»£ng: sinh viÃªn, nhÃ  nghiÃªn cá»©u muá»‘n hiá»ƒu sÃ¢u kiáº¿n trÃºc MAE thÃ´ng qua viá»‡c tá»± implement tá»«ng thÃ nh pháº§n.

## Goals & Objectives

**What do we want to achieve?**

### Primary Goals

1. **TÃ¡ch module rÃµ rÃ ng**: Encoder, Decoder lÃ  cÃ¡c module Ä‘á»™c láº­p, cÃ³ thá»ƒ tÃ¡i sá»­ dá»¥ng
2. **Implement Ä‘áº§y Ä‘á»§ 3 model variants** tá»« paper:
   - `mae_vit_base_patch16` â€” ViT-B/16 (embed_dim=768, depth=12, heads=12, ~111M params)
   - `mae_vit_large_patch16` â€” ViT-L/16 (embed_dim=1024, depth=24, heads=16, ~330M params)
   - `mae_vit_huge_patch14` â€” ViT-H/14 (embed_dim=1280, depth=32, heads=16, **patch_size=14**, ~657M params)
3. **Táº¡o folder `models/` riÃªng biá»‡t** trÃ¬nh bÃ y táº¥t cáº£ model variants kÃ¨m documentation
4. **Verify output** nháº¥t quÃ¡n vá»›i official implementation (`official_mae/models_mae.py`)

### Secondary Goals

- Má»—i module cÃ³ docstring giáº£i thÃ­ch quan há»‡ vá»›i paper (section, equation)
- Factory functions vÃ  model registry thá»‘ng nháº¥t
- Notebook demo cho tá»«ng variant

### Non-goals (explicitly out of scope)

- Training pipeline (pre-training, fine-tuning) â€” sáº½ lÃ  feature riÃªng
- Data loading / augmentation pipeline
- Distributed training utilities
- Fine-tuning head (linear probing, end-to-end fine-tune)

## User Stories & Use Cases

**How will users interact with the solution?**

1. **As a researcher**, I want to instantiate any MAE variant with a single function call so that I can quickly experiment:

   ```python
   from models import mae_vit_base_patch16, mae_vit_large_patch16, mae_vit_huge_patch14
   model = mae_vit_large_patch16()
   loss, pred, mask = model(images)
   ```

2. **As a student**, I want to understand tá»«ng module riÃªng biá»‡t (Encoder, Decoder, Attention, PatchEmbed...) so that I can trace data flow through the architecture:

   ```python
   from mae.encoder import MAEEncoder
   from mae.decoder import MAEDecoder
   encoder = MAEEncoder(embed_dim=768, depth=12, num_heads=12)
   ```

3. **As a developer**, I want a `models/` folder with dedicated files cho tá»«ng variant so that I can compare hyperparameters side-by-side:

   ```
   models/
   â”œâ”€â”€ README.md              # Overview & comparison table
   â”œâ”€â”€ mae_vit_base.py        # ViT-Base variant
   â”œâ”€â”€ mae_vit_large.py       # ViT-Large variant
   â”œâ”€â”€ mae_vit_huge.py        # ViT-Huge variant
   â””â”€â”€ __init__.py            # Factory & registry
   ```

4. **As a reviewer**, I want to verify our implementation matches the official one by comparing parameter counts and output tensors.

## Success Criteria

**How will we know when we're done?**

| Criterion                                           | Measurement                                                                  |
| --------------------------------------------------- | ---------------------------------------------------------------------------- |
| All 3 variants instantiate without error            | Unit test pass                                                               |
| Parameter counts match official Â±0.1%               | `mae_vit_base`: ~111M, `mae_vit_large`: ~330M, `mae_vit_huge`: ~657M         |
| Output shape correct                                | loss scalar, pred `(B, num_patches, patch_sizeÂ²Ã—3)`, mask `(B, num_patches)` |
| `encoder.py` and `decoder.py` fully implemented     | Non-empty, tested independently                                              |
| `models/` folder with all variants + README         | Files exist and documented                                                   |
| Forward pass output matches official (same weights) | Tensor diff < 1e-5                                                           |

## Constraints & Assumptions

**What limitations do we need to work within?**

### Technical Constraints

- ViT-Huge (`patch_size=14`) táº¡o ra **256 patches** (16Ã—16 grid) thay vÃ¬ 196 â€” cáº§n Ä‘áº£m báº£o code xá»­ lÃ½ Ä‘Ãºng
- ViT-Huge yÃªu cáº§u â‰¥32GB VRAM â€” testing trÃªn CPU hoáº·c cáº§n mixed precision
- Táº¥t cáº£ module pháº£i khÃ´ng phá»¥ thuá»™c `timm` (tá»± implement from scratch)

### Assumptions

- Decoder luÃ´n dÃ¹ng cáº¥u hÃ¬nh `embed_dim=512, depth=8, heads=16` cho má»i variant (theo paper)
- Sá»­ dá»¥ng sinusoidal positional embedding (fixed, not learned)
- Input image size cá»‘ Ä‘á»‹nh 224Ã—224

## Questions & Open Items

**What do we still need to clarify?**

- [x] ViT-Huge dÃ¹ng `patch_size=14` â†’ cáº§n verify `num_patches = (224/14)Â² = 256`
- [ ] CÃ³ cáº§n há»— trá»£ variable image size khÃ´ng? (Táº¡m thá»i: No, fix 224Ã—224)
- [ ] Naming convention: dÃ¹ng `MAEViTBase` hay `mae_vit_base_patch16` function?
  - **Decision**: Cáº£ hai â€” Class name PascalCase, factory function snake_case (theo official)

---

## ğŸ¤– Data Requirements (AI/ML Projects)

**What data do we need?**

- **Pre-training**: ImageNet-1K (1.28M images, ~150GB) â€” chÆ°a cáº§n á»Ÿ bÆ°á»›c nÃ y
- **Testing/Demo**: Random tensors hoáº·c single image cho visualization
- **Verification**: Official pretrained weights Ä‘á»ƒ compare output

| Data              | Purpose             | Required Now?       |
| ----------------- | ------------------- | ------------------- |
| Random tensors    | Unit tests          | Yes                 |
| Single test image | Visualization demo  | Nice-to-have        |
| Official weights  | Output verification | Nice-to-have        |
| ImageNet-1K       | Pre-training        | No (future feature) |

## Model Variants (from Paper)

| Config                   | ViT-Base/16 | ViT-Large/16 | ViT-Huge/14 |
| ------------------------ | ----------- | ------------ | ----------- |
| `patch_size`             | 16          | 16           | **14**      |
| `embed_dim`              | 768         | 1024         | 1280        |
| `depth` (encoder blocks) | 12          | 24           | 32          |
| `num_heads` (encoder)    | 12          | 16           | 16          |
| `decoder_embed_dim`      | 512         | 512          | 512         |
| `decoder_depth`          | 8           | 8            | 8           |
| `decoder_num_heads`      | 16          | 16           | 16          |
| `mlp_ratio`              | 4.0         | 4.0          | 4.0         |
| `num_patches`            | 196         | 196          | **256**     |
| Approx. params           | ~111M       | ~330M        | ~657M       |
